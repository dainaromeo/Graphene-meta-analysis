{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import re\n",
    "from matplotlib.ticker import AutoLocator\n",
    "import graphviz\n",
    "from graphviz import render\n",
    "\n",
    "\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function to remove assays and medias with less than 4 occurrences\n",
    "\n",
    "def agg_size_nosort(df):\n",
    "    counts_assay = df.groupby(\"assay\", sort=False)[\"assay\"].transform('size')\n",
    "    counts_media = df.groupby(\"media\", sort=False)[\"media\"].transform('size')\n",
    "    mask = (counts_assay > 3) & (counts_media > 3)\n",
    "    return df[mask]\n",
    "\n",
    "# function to plot data in bins\n",
    "def plot_bar_bin(series, bins, img_name):\n",
    "    '''\n",
    "    plot an histogram with ranges of data as columns\n",
    "    :param series: series of the feature to plot\n",
    "    :param bins: a list with the limit values of the bins\n",
    "    :param img_name: name of the saved figure\n",
    "    :return: histogram of data points in each bin\n",
    "    '''\n",
    "    # general bar plots with 6 bins\n",
    "    to_plot = series.dropna(axis=0)\n",
    "    color = cm.rainbow(np.linspace(0, 1, len(bins) - 1))\n",
    "    fig, ax = plt.subplots()\n",
    "    hist, bin_edges = np.histogram(to_plot, bins)\n",
    "    ax.set_ylim(0, 50)\n",
    "    #ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylabel('Number of data points')\n",
    "    ax.set_xlabel('BMDL range [ug/mL]')\n",
    "    rec = ax.bar(range(len(hist)), hist, width=0.8, align='center', tick_label=\n",
    "    ['{} - {}'.format(bins[i], bins[i + 1]) for i, j in enumerate(hist)], color=color)\n",
    "    plt.xticks(rotation=45)\n",
    "    autolabel(rec, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{img_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2., 1.05 * height,\n",
    "               s= '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "\n",
    "#Function to print positive feature importance based on the Linear SVC coefficients, per class\n",
    "\n",
    "def print_top10(feature_names, clf, x_name, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        coeff = clf.coef_[i]\n",
    "        ordered_coef = [x for x,_ in sorted(zip(coeff,feature_names), key=lambda sublist: abs(sublist[0]))[::-1]]\n",
    "        ordered_names = [y for _,y in sorted(zip(coeff,feature_names), key=lambda sublist: abs(sublist[0]))[::-1]]\n",
    "        ordered_coef_pos = [x for x in ordered_coef[0:10]]\n",
    "        ordered_names_pos = ordered_names[:len(ordered_coef_pos)]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.barh(range(len(ordered_names_pos)), ordered_coef_pos[::-1], align='center')\n",
    "        plt.yticks(range(len(ordered_names_pos)), ordered_names_pos[::-1])\n",
    "\n",
    "        plt.title(f'Feature importance for class {class_label}')\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(f'Graphene//New_plots//BMDL LinearSVC viab 3class coeff2 {x_name} {i}.pdf')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "\n",
    "def confusion_matrix(matrix, tick_names, file_name, data_set_name):\n",
    "        # Plot confusion matrix\n",
    "        figure = plt.figure()\n",
    "        ax = plt.subplot()\n",
    "        im = ax.imshow(matrix, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "        #tick_marks = [0,1,2,3]\n",
    "        tick_marks=[0, 1, 2]\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(tick_names)\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('True')\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\", fontsize=12)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(tick_names)\n",
    "        plt.setp(ax.get_yticklabels(), fontsize=12)\n",
    "        ax.set_ylim(-0.5, 2.5)\n",
    "        # change font color to white to be visible against darkest colors\n",
    "        for (i, j), z in np.ndenumerate(matrix):\n",
    "            if z > 8:\n",
    "                fontcolor = 'white'\n",
    "            else:\n",
    "                fontcolor = 'black'\n",
    "            ax.text(j, i, str(int(z)), ha='center', va='center', color= fontcolor, size=12)\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.grid(None)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{file_name}_{data_set_name}.pdf', dpi=400)\n",
    "        plt.savefig(f'{file_name}_{data_set_name}.png', dpi=400)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################################\n",
    "#   LOADING DATA\n",
    "#################################\n",
    "df_v = pd.read_csv('Graphene/Graphene_BMD_UPDATED_no_outliers.csv')\n",
    "df_v.describe()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################################\n",
    "#   PREPARING DATA FOR ANALYSIS\n",
    "#################################\n",
    "\n",
    "df_v[['new_name', 'species']] = df_v[['new_name', 'species']].applymap(lambda x: x.strip())\n",
    "df_v['func'] = df_v['func'].fillna(0)\n",
    "\n",
    "# keep only alpah numeric characters in media column\n",
    "df_v['media'] = df_v['media'].apply(lambda row: re.sub(r'\\W+', '', row))\n",
    "\n",
    "df_v['assay'] = df_v['assay'].apply(lambda row: row.replace('viability_', ''))\n",
    "\n",
    "print(f'Before removing less than 4 assay and media, size = {len(df_v)}')\n",
    "\n",
    "df_v = agg_size_nosort(df_v)\n",
    "print(f'After removing less than 4 assay and media, size = {len(df_v)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################\n",
    "## SUPERVISED CLASSIFICATION\n",
    "############################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bins = [0, 5, 10, 15, 30, 50, 70, 100, 120, 140, 260]\n",
    "plot_bar_bin(df_v['BMDL'], bins, 'BMDL distribution - viability')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define BMDL classes\n",
    "df_v['BMDL_class'] = np.nan\n",
    "\n",
    "# 4 classes\n",
    "'''\n",
    "df_v.loc[df_v.BMDL < 15, 'BMDL_class'] = 0\n",
    "df_v.loc[(df_v.BMDL >= 15) & (df_v.BMDL < 35), 'BMDL_class'] = 1\n",
    "df_v.loc[(df_v.BMDL >= 35) & (df_v.BMDL < 100), 'BMDL_class'] = 2\n",
    "df_v.loc[df_v.BMDL >= 100, 'BMDL_class'] = 3\n",
    "'''\n",
    "# 3 classes\n",
    "df_v.loc[df_v.BMDL < 15, 'BMDL_class'] = 0\n",
    "df_v.loc[(df_v.BMDL >= 15) & (df_v.BMDL < 60), 'BMDL_class'] = 1\n",
    "df_v.loc[df_v.BMDL >= 60, 'BMDL_class'] = 2\n",
    "\n",
    "# Plot distribution of data in the classes\n",
    "fig = plt.figure()\n",
    "plt.hist(df_v.BMDL_class)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data set 1\n",
    "\n",
    "sc = df_v[['BMDL_class', 'Substance', 'size_class', 'time', 'cell_type', 'assay','func', 'layer', 'z_pot', 'media',\n",
    "           'cell_species','cell_type_general', 'species']].copy()\n",
    "sc.dropna(axis=0, inplace=True)\n",
    "sc.reset_index(drop=True, inplace=True)\n",
    "# categorical variables encoding\n",
    "enc_size = {'S':1, 'M':2, 'L':3}\n",
    "sc['size_class'] = sc['size_class'].apply(lambda row: enc_size[row])\n",
    "sc = pd.get_dummies(sc, columns=['Substance',  'cell_type', 'cell_species', 'cell_type_general', 'species' , 'assay',\n",
    "                                 'media', 'func'], drop_first=True)\n",
    "\n",
    "y_1 = sc['BMDL_class']\n",
    "x_source_1 = sc.drop(labels='BMDL_class', axis=1)\n",
    "\n",
    "# plot distribution of dependent variable\n",
    "fig = plt.figure()\n",
    "plt.hist(y_1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data set 2\n",
    "\n",
    "sc2 = df_v[['BMDL_class', 'Substance', 'size_class', 'time', 'cell_type', 'assay','func',  'cell_species', 'media',\n",
    "            'cell_type_general', 'species']].copy()\n",
    "\n",
    "enc_size = {'S':1, 'M':2, 'L':3}\n",
    "sc2.dropna(axis=0, inplace=True)\n",
    "sc2.reset_index(drop=True, inplace=True)\n",
    "# categorical variables encoding\n",
    "sc2['size_class'] = sc2['size_class'].apply(lambda row: enc_size[row])\n",
    "sc2 = pd.get_dummies(sc2, columns=['Substance',  'cell_type', 'cell_species', 'cell_type_general', 'species' , 'assay',\n",
    "                                   'func', 'media'], drop_first=True)\n",
    "\n",
    "y_big = sc2['BMDL_class']\n",
    "x_source_big = sc2.drop(labels='BMDL_class', axis=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(y_big)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data set 3\n",
    "\n",
    "sc3 = df_v[['BMDL_class', 'Substance', 'size_class', 'time', 'cell_type', 'assay','func',  'cell_species', 'media',\n",
    "            'cell_type_general', 'species', 'layer']].copy()\n",
    "\n",
    "enc_size = {'S':1, 'M':2, 'L':3}\n",
    "sc3.dropna(axis=0, inplace=True)\n",
    "sc3.reset_index(drop=True, inplace=True)\n",
    "# categorical variables encoding\n",
    "sc3['size_class'] = sc3['size_class'].apply(lambda row: enc_size[row])\n",
    "sc3 = pd.get_dummies(sc3, columns=['Substance',  'cell_type', 'cell_species', 'cell_type_general', 'species' , 'assay',\n",
    "                                   'func', 'media'], drop_first=True)\n",
    "\n",
    "y_layer = sc3['BMDL_class']\n",
    "x_source_l = sc3.drop(labels='BMDL_class', axis=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(y_layer)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run this to select data set 1\n",
    "\n",
    "y = y_1\n",
    "x_source = x_source_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run this to select data set 2\n",
    "\n",
    "y = y_big\n",
    "x_source = x_source_big"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run this to select data set 3\n",
    "\n",
    "y = y_layer\n",
    "x_source = x_source_l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_source.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##############################\n",
    "# SVM classifier\n",
    "#############################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "# pipeline that scales the data and fits a Linear SVC\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('SVC', LinearSVC(C=1, loss='hinge', max_iter=100000))])\n",
    "\n",
    "X = x_source\n",
    "# keep track of selected parameters and corresponding model R2\n",
    "parameters = []\n",
    "score = []\n",
    "\n",
    "# Sequential feature selector\n",
    "for n_param in range(2,len(X.columns)):\n",
    "    sfs = SequentialFeatureSelector(estimator=pipe, n_features_to_select=n_param)\n",
    "    sfs.fit(X, y)\n",
    "    new_x = sfs.transform(X)\n",
    "    parameters.extend([sfs.get_support()])\n",
    "    # cross validation - one R2 for each cross val run\n",
    "    score.append(cross_val_score(pipe, new_x, y, cv=LeaveOneOut()))\n",
    "\n",
    "# for each number of parameters tested report the R2 of Cross validation as the mean of each run\n",
    "score_synt = [np.mean(x) for x in score]\n",
    "print(f'SVC Model prediction (LOOCV) Accuracy for 2 to {len(X.columns)-1} features included: {score_synt}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract multiple sets of independent variables based on the results of feature selection by choosing the highest score_synt and selecting the corresponding position in parameters\n",
    "\n",
    "# use also all features (x_tot)\n",
    "\n",
    "# depending on the data set used the sets change - comment the ones that are not used.\n",
    "\n",
    "x_68 = X.loc[:, parameters[4]].copy()\n",
    "'''\n",
    "x_tot = X[['size_class', 'time', 'layer', 'z_pot', 'Substance_Graphene oxide',\n",
    "       'Substance_rGO', 'cell_type_BEAS- 2B', 'cell_type_J774.A1',\n",
    "       'cell_type_THP-1', 'cell_species_macrophage_human',\n",
    "       'cell_species_macrophage_rodent', 'cell_type_general_macrophage',\n",
    "       'species_rodent', 'assay_mtt', 'assay_pi', 'assay_wst',\n",
    "       'media_DMEM10FBS', 'media_DMEMF1210FBS', 'media_F1210FBS',\n",
    "       'media_RPMI10FBS', 'func_NH2', 'func_PAA', 'func_PAM', 'func_PEG',\n",
    "       'func_hydrated']]\n",
    "\n",
    "\n",
    "\n",
    "# FOR LARGE DATASET\n",
    "x_14 = X.loc[:, parameters[16]].copy()\n",
    "x_tot_big = X[['size_class', 'time', 'Substance_Graphene oxide', 'Substance_rGO',\n",
    "       'cell_type_BEAS- 2B', 'cell_type_J774.A1', 'cell_type_THP-1',\n",
    "       'cell_species_macrophage_human', 'cell_species_macrophage_rodent',\n",
    "       'cell_type_general_macrophage', 'species_rodent', 'assay_ez_cyto',\n",
    "       'assay_ldh', 'assay_mtt', 'assay_pi', 'assay_wst', 'func_COOH',\n",
    "       'func_Fe3O4', 'func_NH2', 'func_PAA', 'func_PAM', 'func_PEG',\n",
    "       'func_hydrated', 'media_DMEM10FBS', 'media_DMEMF1210FBS',\n",
    "       'media_F1210FBS', 'media_RPMI10FBS']]\n",
    "'''\n",
    "# For layer dataset\n",
    "\n",
    "x_tot_l = X[['size_class', 'time', 'layer', 'Substance_Graphene oxide',\n",
    "       'Substance_rGO', 'cell_type_BEAS- 2B', 'cell_type_J774.A1',\n",
    "       'cell_type_THP-1', 'cell_species_macrophage_human',\n",
    "       'cell_species_macrophage_rodent', 'cell_type_general_macrophage',\n",
    "       'species_rodent', 'assay_ez_cyto', 'assay_ldh', 'assay_mtt', 'assay_pi',\n",
    "       'assay_wst', 'func_COOH', 'func_NH2', 'func_PAA', 'func_PAM',\n",
    "       'func_PEG', 'func_hydrated', 'media_DMEM10FBS', 'media_DMEMF1210FBS',\n",
    "       'media_F1210FBS', 'media_RPMI10FBS']]\n",
    "\n",
    "x_68l = X.loc[:, parameters[22]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# choose which set of independent variables to use\n",
    "x_to_use = x_tot_l\n",
    "# name to use in the figures to save\n",
    "x_name = 'all_61_l'\n",
    "\n",
    "x_to_use.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tune the parameters via GridSearcCV\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('SVC', LinearSVC(loss='hinge', max_iter=10000000))])\n",
    "search_space = [{'SVC__C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}]\n",
    "pipe_svc = GridSearchCV(pipe, search_space, cv=LeaveOneOut())\n",
    "pipe_svc.fit(x_to_use, y)\n",
    "\n",
    "# print best C value and R2\n",
    "best_C = pipe_svc.best_params_\n",
    "print(best_C)\n",
    "print(pipe_svc.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print top 10 features\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "feature_names = [x for x in x_to_use.columns]\n",
    "#class_names = ['BMDL < 12', '12<=BMDL<25', '25<=BMDL<50', 'BMDL>=50']\n",
    "class_names = ['BMDL < 15', '15<=BMDL<60', 'BMDL>=60']\n",
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(x_to_use)\n",
    "svm = LinearSVC(C=best_C['SVC__C'], loss='hinge', max_iter=10000000)\n",
    "svm.fit(X_norm, y)\n",
    "\n",
    "print_top10(feature_names, svm, x_name, class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Final model, confusion matrix and performance metics\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "# and get accuracy measures\n",
    "pipe_svc2 = Pipeline([('scaler', MinMaxScaler()), ('SVC', LinearSVC(C=best_C['SVC__C'], loss='hinge',  max_iter=100000))])\n",
    "loo = LeaveOneOut()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "x_source2 = np.array(x_to_use)\n",
    "#Fit model and get predictions via LOOCV\n",
    "for train_index, test_index in loo.split(x_source2):\n",
    "    X_train, X_test = x_source2[train_index], x_source2[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    pipe_svc2.fit(X_train, y_train)\n",
    "    preds = pipe_svc2.predict(X_test)\n",
    "    y_true.extend(y_test)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "# Accuracy score\n",
    "accuracy_avg = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y, y_pred)\n",
    "#tick_names = ['BMDL < 12', '12<=BMDL<25', '25<=BMDL<50', 'BMDL>=50']\n",
    "tick_names = ['BMDL < 15', '15<=BMDL<60', 'BMDL>=60']\n",
    "\n",
    "confusion_matrix(confusion, 'Graphene//New_plots//SVC_confusion_matrix_3class', x_name )\n",
    "# Multiple performance metrics\n",
    "recap = metrics.classification_report(y_true, y_pred, target_names=tick_names)\n",
    "print(recap)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###############################\n",
    "# Decision tree classifier\n",
    "###############################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# select data set - change accordingly\n",
    "\n",
    "y = y_layer\n",
    "x_source = x_source_l\n",
    "x_source.columns\n",
    "x_name = 'all_l_61'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find optimal max depth and min sample split via GridSearchCV\n",
    "tree_class = DecisionTreeClassifier(class_weight='balanced')\n",
    "search_space = [{'max_depth': [x for x in range(3,6)], 'min_samples_split': [x for x in range(2, 6)]}]\n",
    "tree_res = GridSearchCV(tree_class, search_space, cv=LeaveOneOut())\n",
    "tree_res.fit(x_source, y)\n",
    "print(tree_res.best_params_)\n",
    "print(tree_res.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Input best parameters from above and fit model\n",
    "tree_class2 = DecisionTreeClassifier(class_weight='balanced', max_depth=tree_res.best_params_['max_depth'], min_samples_split=tree_res.best_params_['min_samples_split'])\n",
    "loo = LeaveOneOut()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "x_source2 = np.array(x_source)\n",
    "for train_index, test_index in loo.split(x_source2):\n",
    "    X_train, X_test = x_source2[train_index], x_source2[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    tree_class2.fit(X_train, y_train)\n",
    "    preds = tree_class2.predict(X_test)\n",
    "    y_true.extend(y_test)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "accuracy_avg = metrics.accuracy_score(y_true, y_pred)\n",
    "print(accuracy_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion = metrics.confusion_matrix(y, y_pred)\n",
    "#tick_names = ['BMDL < 12', '12<=BMDL<25', '25<=BMDL<50', 'BMDL>=50']\n",
    "tick_names = ['BMDL < 15', '15<=BMDL<60',  'BMDL>=60']\n",
    "confusion_matrix(confusion, 'Graphene//New_plots//Decision_tree_confusion_matrix_3class', x_name )\n",
    "# performance metrics\n",
    "recap = metrics.classification_report(y_true, y_pred, target_names=tick_names)\n",
    "print(recap)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Draw tree\n",
    "feature_names = x_source.columns\n",
    "dot_data = export_graphviz(tree_res.best_estimator_, out_file=f'Graphene//New_plots//Decision_tree_classifier_3class_cat_15-60_balanced_{x_name}.dot',\n",
    "            filled=True, rounded=True, feature_names=feature_names, class_names=['BMDL < 15', '15<=BMDL<60',  'BMDL>=60'])\n",
    "\n",
    "render('dot', 'png', f'Graphene//New_plots//Decision_tree_classifier_3class_cat_15-60_balanced_{x_name}.dot')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##############################\n",
    "# Random Forest classifier\n",
    "##############################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find optimal max depth and min sample split via GridSearchCV\n",
    "forest_class = RandomForestClassifier()\n",
    "search_space = [{'n_estimators': [10], 'max_depth': [x for x in range(3,6)], 'min_samples_split': [x for x in range(2, 6)]}]\n",
    "forest_res = GridSearchCV(forest_class, search_space, cv=LeaveOneOut())\n",
    "forest_res.fit(x_source, y)\n",
    "print(forest_res.best_params_)\n",
    "print(forest_res.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Input best parameters from above\n",
    "forest_class2 = RandomForestClassifier(n_estimators=10, max_depth=forest_res.best_params_['max_depth'], min_samples_split=forest_res.best_params_['min_samples_split'])\n",
    "loo = LeaveOneOut()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "x_source2 = np.array(x_source)\n",
    "for train_index, test_index in loo.split(x_source2):\n",
    "    X_train, X_test = x_source2[train_index], x_source2[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    forest_class2.fit(X_train, y_train)\n",
    "    preds = forest_class2.predict(X_test)\n",
    "    y_true.extend(y_test)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "# evaluate the model\n",
    "cv = LeaveOneOut()\n",
    "n_scores = cross_val_score(forest_class2, x_source2, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "accuracy_avg = metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "print(accuracy_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y, y_pred)\n",
    "#tick_names = ['BMDL < 12', '12<=BMDL<25', '25<=BMDL<50', 'BMDL>=50']\n",
    "tick_names = ['BMDL < 15', '15<=BMDL<60',  'BMDL>=60']\n",
    "confusion_matrix(confusion, 'Graphene//New_plots//Random_forest_confusion_matrix_3class', x_name )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}