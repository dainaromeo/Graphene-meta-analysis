{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "import scipy\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score as r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#   LOADING DATA\n",
    "#################################\n",
    "graph = pd.read_csv(r'C:\\Code\\grm\\First Analysis\\data\\Graphene_for_BMD_UPDATE.csv')\n",
    "graph.rename(columns={'variable':'assay'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#   PREPARING DATA FOR ANALYSIS\n",
    "#################################\n",
    "# Combine the graphene type name and the functionalization in a unique feature called new_name (used in regression)\n",
    "graph.func.fillna('', inplace=True)\n",
    "graph.loc[graph.layer ==0.0, 'layer'] = np.nan\n",
    "# Data set for viability endpoints - df_v\n",
    "viability_list = ['nucleo', 'alive','cfa', 'viability_alamar', 'ez_cyto', 'viability_pi',\n",
    "       'viability_ldh', 'viability_mtt',  'viability_cck', 'viability_wst', 'neutral_red', 'viability_hymolisis']\n",
    "graph = graph.loc[graph['assay'].isin(viability_list), :].copy()\n",
    "# Remove viability_\n",
    "graph['assay'] = graph['assay'].apply(lambda row: row.replace('viability_', ''))\n",
    "# keep only alpha numeric characters in media column  \n",
    "graph['media'] = graph['media'].apply(lambda row: re.sub(r'\\W+', '', row))\n",
    "df_v = graph.copy() \n",
    "df_analysis = df_v[['size_class', 'layer', 'z_pot', 'time', 'cell_type_general',\n",
    "                'assay', 'Substance', 'func', 'type', 'media', 'bmd_id', 'species' , 'dose', 'value']].copy() \n",
    "#Remove nan rows from layer\n",
    "df_analysis.dropna(subset=['layer'], inplace=True)\n",
    "df_analysis.reset_index(drop=True, inplace=True)\n",
    "#Replace with 100 responses higher than 100\n",
    "df_analysis['value'] = df_analysis['value'].apply(lambda row: 100 if row > 100 else row)\n",
    "#Remove rows with dose 0\n",
    "df_analysis = df_analysis[df_analysis['dose']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861a0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vizualizaing the head of the data set\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d961d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis[['dose']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many data points are in the data set?\n",
    "len(df_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1615ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique experiments are in the data set?\n",
    "len(df_analysis.bmd_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove assays and medias with less than 4 occurrences\n",
    "filter_df = pd.DataFrame()\n",
    "elements = 3\n",
    "for column in ['assay', 'media']:\n",
    "    print(df_analysis.groupby(by=column, as_index=False).agg({'bmd_id': pd.Series.nunique}).sort_values(by='bmd_id', ascending=False))    \n",
    "    a_df = df_analysis.groupby(by=column, as_index=False).agg({'bmd_id': pd.Series.nunique}).sort_values(by='bmd_id', ascending=False)\n",
    "    columns = a_df[a_df['bmd_id']>elements][column].values\n",
    "    if len(filter_df)==0:\n",
    "        filter_df = df_analysis[df_analysis.apply(lambda row: row[column] in columns, axis=1)]\n",
    "    else:\n",
    "        filter_df = filter_df[filter_df.apply(lambda row: row[column] in columns, axis=1)]\n",
    "df_analysis = filter_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05726366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many data points remain in the data set?\n",
    "len(df_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae202dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many experiments remain in the data set?\n",
    "len(df_analysis.bmd_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#   Model Fitting\n",
    "#################################\n",
    "#Models\n",
    "#Model 1: Y[dose] = a * x + b\n",
    "#Model 2: Y[dose] = a *x**2 + b*x**1 + c\n",
    "#Model 3: Y[dose] = a * exp {sign * b * dose}\\n a*np.exp(b*x)\n",
    "#Model 4: Y[dose] = a * exp{sign * (b * dose) ^ d}\\n\n",
    "#Model 5: Y[dose] = a * [c - (c - 1) * exp{-b * dose}]\\n\n",
    "#Model 6: Y[dose] = a * [c - (c - 1) * exp{-(b * dose) ^ d}]\\n\\n\n",
    "#Model 7: Y[dose] = intercept + v*dose^n/(k^n + dose^n)\\n\\n\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute the model\n",
    "def func(model, x, *param):\n",
    "    if model==1:\n",
    "        a, b = param\n",
    "        return a*x + b\n",
    "    elif model==2:\n",
    "        a, b, c = param\n",
    "        return a*x**2 + b*x**1 + c\n",
    "    elif model==3:\n",
    "        a, b = param        \n",
    "        return a*np.exp(b*x)\n",
    "    elif model==4:\n",
    "        a, b, d = param\n",
    "        return a * np.exp(b * x)**d\n",
    "    elif model==5:\n",
    "        a, b, c = param\n",
    "        return a * (c - (c - 1.0) * np.exp(-1.0 * (b * x)))\n",
    "    elif model==6:\n",
    "        a, b, c, d = param\n",
    "        return a * (c - (c - 1.0) * np.exp(-1.0 * np.power(b * x, d)))\n",
    "    elif model==7:\n",
    "        intercept, v, k, n = param \n",
    "        return intercept + v*x**n/(k**n + x**n)\n",
    "\n",
    "#Function to fit the curve to the model    \n",
    "def fitCurve(model, xdata, ydata):\n",
    "    if model==1:\n",
    "        return scipy.optimize.curve_fit(lambda x,a,b: a*x + b, xdata, ydata)\n",
    "    elif model==2:\n",
    "        return scipy.optimize.curve_fit(lambda x,a,b,c: a*x**2 + b*x**1 + c, xdata, ydata)    \n",
    "    elif model==3:\n",
    "        return scipy.optimize.curve_fit(lambda x,a,b: a*np.exp(b*x), xdata, ydata)\n",
    "    elif model==4:        \n",
    "        return scipy.optimize.curve_fit(lambda x,a,b,d: a * np.exp(b*x)**d, xdata, ydata)\n",
    "    elif model==5:        \n",
    "         return scipy.optimize.curve_fit(lambda x,a,b,c: a * (c - (c - 1.0) * np.exp(-1.0 * (b * x))), xdata, ydata)\n",
    "    elif model==6:        \n",
    "        return scipy.optimize.curve_fit(lambda x,a,b,c,d: a * (c - (c - 1.0) * np.exp(-1.0 * np.power(b * x, d))), xdata, ydata)\n",
    "    elif model==7:        \n",
    "        return scipy.optimize.curve_fit(lambda x,intercept,v,k,n: intercept + v*x**n/(k**n + x**n), xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#   Compute the new sampling for dose\n",
    "#################################\n",
    "#Parameters for this cell\n",
    "min_dataPoints = 3 # minimun number of data points\n",
    "num_values = 10 #Number of samples \n",
    "#set min and max value for each experiment\n",
    "def get_range(row):\n",
    "    if len(row ['dose'])>=min_dataPoints and max(row ['dose'])>=100 and min(row ['dose'])<50:        \n",
    "        return pd.Series([min(row ['dose']),max(row ['dose'])])\n",
    "    else:\n",
    "        return pd.Series([-10000,10000])\n",
    "\n",
    "range_analysis = df_analysis[['dose','bmd_id']].groupby(by='bmd_id').apply(lambda row: get_range(row))\n",
    "range_analysis = range_analysis[range_analysis[0]!=-10000]\n",
    "maxDownVal = max(range_analysis[0])\n",
    "minUpVal = min(range_analysis[1])\n",
    "print(\"Max Down Value: \"+ str(maxDownVal))\n",
    "print(\"Min Up Value: \" + str(minUpVal))\n",
    "xdoseValues = np.linspace(maxDownVal, minUpVal, num=num_values)\n",
    "#Eliminate from the dataset data points which are not inside of maxDownVal and minUpVal\n",
    "df_analysis = df_analysis[df_analysis['bmd_id'].isin(range_analysis.index)]\n",
    "df_analysis.reset_index(inplace=True, drop=True)\n",
    "print('Data Points in the Data Set: ' + str(len(df_analysis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df09a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#   Compute the new sampling for dose\n",
    "#################################\n",
    "\n",
    "#Parameters for this cell\n",
    "plot = False\n",
    "models = [1,2,3,4]\n",
    "\n",
    "if plot:\n",
    "    fig = plt.figure(figsize=(20,800))\n",
    "    axs = fig.subplots(len(df_analysis.bmd_id.unique())*len(models))\n",
    "i = 0\n",
    "\n",
    "mae = {}\n",
    "summary = pd.DataFrame()\n",
    "mean_mae = []\n",
    "value_df = pd.DataFrame()\n",
    "parameter_df = pd.DataFrame()\n",
    "model_c = 1\n",
    "# Compute each model\n",
    "for model in models:\n",
    "    mae[model] = []\n",
    "    print('Processing Model: ' + str(model))\n",
    "    for id_f in df_analysis.bmd_id.unique():\n",
    "        print('Processing bmd_id: ' + str(id_f))        \n",
    "        filter_df = df_analysis[df_analysis['bmd_id']==id_f]\n",
    "        filter_df.sort_values(by=['dose'], inplace=True)\n",
    "        filter_df.reset_index(drop=True, inplace=True)        \n",
    "        xdata = np.array(filter_df['dose'].values)       \n",
    "        ydata = np.array(filter_df['value'].values) \n",
    "        xdata.astype(np.float64)  \n",
    "        ydata.astype(np.float64)      \n",
    "        popt, pcov = fitCurve(model, xdata, ydata)              \n",
    "        ypred = func(model, xdata, *popt)  \n",
    "        if plot:            \n",
    "            axs[i].plot(xdata, ypred, 'r-', label= str(id_f))\n",
    "            axs[i].scatter(xdata, ydata)\n",
    "            axs[i].title.set_text('Model: '+ str(model) + ' bmd_id: '+str(id_f))\n",
    "            i = i+1\n",
    "\n",
    "        meanAbsoluteError = mean_absolute_error(ydata, ypred)            \n",
    "        mae[model].append(meanAbsoluteError)             \n",
    "\n",
    "        ##Save the data\n",
    "        v_df = pd.DataFrame()\n",
    "        p_df = pd.DataFrame()\n",
    "        \n",
    "        v_df['model_' + str(model) +'_values'] = func(model, xdoseValues, *popt)\n",
    "        v_df['xdose'] = xdoseValues\n",
    "              \n",
    "        p_df['model_' + str(model) +'_a'] = [popt[0]]\n",
    "        p_df['model_' + str(model) +'_b'] = [popt[1]]  \n",
    "        p_df['model_' + str(model) +'_mae'] = meanAbsoluteError  \n",
    "        if model==4:                \n",
    "            p_df['model_' + str(model) +'_d'] = [popt[2]]   \n",
    "        elif model==5 or model==2:                \n",
    "            p_df['model_' + str(model) +'_c'] = [popt[2]]\n",
    "        elif model==6 or model==7:                \n",
    "            p_df['model_' + str(model) +'_c'] =  [popt[2]]\n",
    "            p_df['model_' + str(model) +'_d'] =  [popt[3]]                  \n",
    "        if model_c == 1: #if this is the first model start creating a new dataframe\n",
    "            for col in filter_df.columns:\n",
    "                v_df[col] = filter_df.loc[0,col]\n",
    "                p_df[col] = filter_df.loc[0,col]\n",
    "            if len(value_df)==0:\n",
    "                value_df = v_df\n",
    "            else:\n",
    "                value_df = pd.concat([value_df,v_df])\n",
    "            if len(parameter_df)==0:\n",
    "                parameter_df = p_df\n",
    "            else:\n",
    "                parameter_df = pd.concat([parameter_df,p_df])                 \n",
    "        else:                   \n",
    "            value_df.loc[value_df['bmd_id']==id_f,v_df.columns] = v_df\n",
    "            parameter_df.loc[parameter_df['bmd_id']==id_f,p_df.columns] = p_df   \n",
    "    model_c = model_c + 1\n",
    "    mean_mae.append(np.mean(mae[model]))\n",
    "#Compute the mean absolute error\n",
    "value_df.reset_index(drop=True, inplace=True)\n",
    "parameter_df.reset_index(drop=True, inplace=True)\n",
    "summary['model'] = models\n",
    "summary['mean_mae'] = mean_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8899d47b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary=summary.sort_values(by='mean_mae')\n",
    "summary.reset_index(drop=True, inplace=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many data points remain in the dataset?\n",
    "len(value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed925a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many unique experiments remain in the dataset\n",
    "len(value_df.bmd_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af49289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns accordig to the best model\n",
    "model = summary.loc[0,'model']\n",
    "\n",
    "general_columns = ['Substance', 'func', 'size_class', 'layer', 'time', 'cell_type_general', 'species', 'assay', 'type', 'media']\n",
    "\n",
    "value_column = ['model_' + str(model) +'_values']\n",
    "\n",
    "parameter_column = ['model_' + str(model) +'_a', 'model_' + str(model) +'_b']              \n",
    "if model==3:                \n",
    "    parameter_column.append('model_' + str(model) +'_d')   \n",
    "elif model==4 or model==2:                \n",
    "    parameter_column.append('model_' + str(model) +'_c')\n",
    "elif model==5 or model==6:                \n",
    "    parameter_column.append('model_' + str(model) +'_c')\n",
    "    parameter_column.append('model_' + str(model) +'_d')\n",
    "dose_column = ['xdose']\n",
    "mae_column = ['model_' + str(model) +'_mae']\n",
    "\n",
    "valueDS_df = value_df [general_columns + dose_column + value_column+['bmd_id']]\n",
    "parameterDS_df = parameter_df[general_columns + parameter_column + mae_column+['bmd_id']]\n",
    "valueDS_df = valueDS_df.rename(columns={dose_column[0]: 'dose'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5da41c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Encoding\n",
    "col_continuous_value = ['layer', 'time', 'dose'] \n",
    "col_continuous_parameter = ['layer', 'time']\n",
    "col_categorical = ['Substance','func','cell_type_general', 'species','assay', 'media']\n",
    "\n",
    "def encoding(data_df, value, col_continuous):\n",
    "    enc_size = {'S':1, 'M':2, 'L':3}   \n",
    "    dataset_df = pd.get_dummies(data_df[col_categorical], prefix=col_categorical)\n",
    "    dataset_df['size_class'] = data_df['size_class'].apply(lambda row: enc_size[row])\n",
    "    dataset_df[col_continuous] = data_df[col_continuous]\n",
    "    dataset_df[value] = data_df[value]\n",
    "    return dataset_df\n",
    "\n",
    "valueDS2_df = encoding(valueDS_df, value_column[0], col_continuous_value)\n",
    "parameterDS2_df = encoding(parameterDS_df, parameter_column, col_continuous_parameter)\n",
    "valueDS2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82edfb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normalize the data\n",
    "def normalize (dataset_df, col_continuous):\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset_df[col_continuous+['size_class']] = scaler.fit_transform(dataset_df[col_continuous+['size_class']])\n",
    "    dataset_df[col_continuous+['size_class']].head()\n",
    "    return dataset_df\n",
    "\n",
    "valueDS2_df = normalize(valueDS2_df, col_continuous_value)\n",
    "parameterDS2_df = normalize(parameterDS2_df, col_continuous_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78df851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset to predict response\n",
    "model_ds = 'value' #parameter\n",
    "if model_ds=='value':    \n",
    "    x_columns = [col for col in valueDS2_df.columns if col != value_column[0]]\n",
    "    y_columns = value_column\n",
    "    data_df = valueDS2_df\n",
    "elif model_ds =='parameter': \n",
    "    x_columns = [col for col in parameterDS2_df.columns if not(col in parameter_column)]\n",
    "    y_columns = parameter_column\n",
    "    data_df = parameterDS2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X =  data_df[x_columns].values\n",
    "if model_ds=='value':    \n",
    "    y =  data_df[y_columns].values.ravel()    \n",
    "elif model_ds =='parameter':\n",
    "    y =  data_df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21377a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# MLPRegressor\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare the cross-validation procedure\n",
    "# LOOCV\n",
    "cv = LeaveOneOut()\n",
    "cv2 = RepeatedKFold(n_splits=5, n_repeats=1, random_state=3)\n",
    "# create model\n",
    "model = MLPRegressor(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(5, 2), random_state=1, max_iter=10000)\n",
    "# OLD evaluation model\n",
    "scores = cross_val_score(model, X, y, scoring='r2', cv=cv2)\n",
    "print('5Fold crossval R2: %f (%f)' % (np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "# NEW EVALUATION OF MODEL\n",
    "# evaluate model fitting\n",
    "model.fit(X, y)\n",
    "fitting = model.score(X, y, sample_weight=None)\n",
    "print(f'Model fitting R2: {fitting}')\n",
    "# evaluate model\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "r2_score = round(r2(y,y_pred),3)\n",
    "# report performance\n",
    "print(f'LOOCV R2: {r2_score}')\n",
    "\n",
    "# Or with Mean Square Error as metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "print(); print(\"Mean Squared Error: \", results.mean()); print(\"Standard Deviation: \", results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# GradientBoostingRegressor\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2206f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the cross-validation procedure\n",
    "# NEW LOOCV\n",
    "cv = LeaveOneOut()\n",
    "cv2 = RepeatedKFold(n_splits=5, n_repeats=1, random_state=3)\n",
    "# create model\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "# OLD evaluation model\n",
    "scores = cross_val_score(model, X, y, scoring='r2', cv=cv2)\n",
    "print('5Fold crossval R2: %f (%f)' % (np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "# NEW EVALUATION OF MODEL\n",
    "# evaluate model fitting\n",
    "model.fit(X, y)\n",
    "fitting = model.score(X, y, sample_weight=None)\n",
    "print(f'Model fitting R2: {fitting}')\n",
    "# evaluate model\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "r2_score = round(r2(y,y_pred),3)\n",
    "# report performance\n",
    "print(f'LOOCV R2: {r2_score}')\n",
    "\n",
    "# Or with Mean Square Error as metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "print(); print(\"Mean Squared Error: \", results.mean()); print(\"Standard Deviation: \", results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2077f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Feature Importance\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0eefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "values = model.feature_importances_\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"score\"] = values\n",
    "data = data.sort_values(by = \"score\", ascending=False)\n",
    "data.reset_index(inplace=True)\n",
    "data['index'] = data['index'].apply(lambda row: data_df.columns[int(row)])\n",
    "data = data.loc[0:10].set_index('index')\n",
    "data.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04111fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Bayesian Ridge Regressor\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b66c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the cross-validation procedure\n",
    "# NEW LOOCV\n",
    "cv = LeaveOneOut()\n",
    "cv2 = RepeatedKFold(n_splits=5, n_repeats=1, random_state=3)\n",
    "# create model\n",
    "model = BayesianRidge()\n",
    "# OLD evaluation model\n",
    "scores = cross_val_score(model, X, y, scoring='r2', cv=cv2)\n",
    "print('5Fold crossval R2: %f (%f)' % (np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "# NEW EVALUATION OF MODEL\n",
    "# evaluate model fitting\n",
    "model.fit(X, y)\n",
    "fitting = model.score(X, y, sample_weight=None)\n",
    "print(f'Model fitting R2: {fitting}')\n",
    "# evaluate model\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "r2_score = round(r2(y,y_pred),3)\n",
    "# report performance\n",
    "print(f'LOOCV R2: {r2_score}')\n",
    "\n",
    "# Or with Mean Square Error as metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "print(); print(\"Mean Squared Error: \", results.mean()); print(\"Standard Deviation: \", results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Random Forest Regressor\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5cecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the cross-validation procedure\n",
    "cv2 = RepeatedKFold(n_splits=5, n_repeats=1, random_state=3)\n",
    "cv = LeaveOneOut()\n",
    "# create model\n",
    "model = RandomForestRegressor(random_state=1)\n",
    "# OLD evaluation model\n",
    "scores = cross_val_score(model, X, y, scoring='r2', cv=cv2)\n",
    "print('5Fold crossval R2: %f (%f)' % (np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "# NEW EVALUATION OF MODEL\n",
    "# evaluate model fitting\n",
    "model.fit(X, y)\n",
    "fitting = model.score(X, y, sample_weight=None)\n",
    "print(f'Model fitting R2: {fitting}')\n",
    "# evaluate model\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "r2_score = round(r2(y,y_pred),3)\n",
    "# report performance\n",
    "print(f'LOOCV R2: {r2_score}')\n",
    "\n",
    "# Or with Mean Square Error as metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "print(); print(\"Mean Squared Error: \", results.mean()); print(\"Standard Deviation: \", results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# XGBoost\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the cross-validation procedure\n",
    "cv2 = RepeatedKFold(n_splits=5, n_repeats=1, random_state=3)\n",
    "cv = LeaveOneOut()\n",
    "# create model\n",
    "model = XGBRegressor()\n",
    "# evaluate model\n",
    "# OLD evaluation model\n",
    "scores = cross_val_score(model, X, y,  cv=cv2)\n",
    "print('5Fold crossval R2: %f (%f)' % (np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "# NEW EVALUATION OF MODEL\n",
    "# evaluate model fitting\n",
    "model.fit(X, y)\n",
    "fitting = model.score(X, y, sample_weight=None)\n",
    "print(f'Model fitting R2: {fitting}')\n",
    "# evaluate model\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "r2_score = round(r2(y,y_pred),3)\n",
    "# report performance\n",
    "print(f'LOOCV R2: {r2_score}')\n",
    "\n",
    "# Or with Mean Square Error as metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "print(); print(\"Mean Squared Error: \", results.mean()); print(\"Standard Deviation: \", results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Voting Regressor\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the cross-validation procedure\n",
    "# NEW LOOCV\n",
    "cv = LeaveOneOut()\n",
    "cv2 = RepeatedKFold(n_splits=5, n_repeats=1, random_state=3)\n",
    "# create model\n",
    "reg1 = MLPRegressor(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(5, 2), random_state=1, max_iter=10000)\n",
    "reg2 = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "model = VotingRegressor(estimators=[('mlpr', reg1), ('gbr',reg2)])\n",
    "# OLD evaluation model\n",
    "scores = cross_val_score(model, X, y, scoring='r2', cv=cv2)\n",
    "print('5Fold crossval R2: %f (%f)' % (np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "# NEW EVALUATION OF MODEL\n",
    "# evaluate model fitting\n",
    "model.fit(X, y)\n",
    "fitting = model.score(X, y, sample_weight=None)\n",
    "print(f'Model fitting R2: {fitting}')\n",
    "# evaluate model\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "r2_score = round(r2(y,y_pred),3)\n",
    "# report performance\n",
    "print(f'LOOCV R2: {r2_score}')\n",
    "\n",
    "# Or with Mean Square Error as metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "results = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "print(); print(\"Mean Squared Error: \", results.mean()); print(\"Standard Deviation: \", results.std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8b55665b2a100c1cf002a3856f5ec76c9dcf62e2257da454c3345c911f24dc9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('grm2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
